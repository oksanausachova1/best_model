{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZwZ7RMtSMBF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "from functools import partial\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import cross_val_score,train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from math import sqrt\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_reg(model, model_name, x_train, y_train, x_test, y_test):\n",
        "  model.fit(x_train,y_train)\n",
        "  y_test_pred = model.predict(x_test)\n",
        "  y_train_pred = model.predict(x_train)\n",
        "\n",
        "  r2_train = r2_score(y_train, y_train_pred)\n",
        "  r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "  mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "  mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "  \n",
        "  rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "  rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "\n",
        "  scores = {\n",
        "      'r2': {'train':r2_train, 'val': r2_test},\n",
        "      'rmse': {'train':rmse_train, 'val': rmse_test},\n",
        "      'mae': {'train':mae_train, 'val': mae_test}\n",
        "  }\n",
        "  \n",
        "  plt.scatter(y_test,y_test_pred, s=5)\n",
        "  plt.xlabel('GT')\n",
        "  plt.ylabel('Predicted')\n",
        "  plt.gca().set_aspect('equal')\n",
        "  plt.title(model_name)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  \n",
        "  return scores\n",
        "\n",
        "def plot_r2(model_names, model_scores_t, model_scores_v):\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel(r'$R^2$')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.ylim(-0.1, 1)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_score_reg(model_names, model_scores_t, model_scores_v):\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('score')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_mae(model_names, model_scores_t, model_scores_v):\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('MAE')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_rmse(model_names, model_scores_t, model_scores_v):\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()    \n"
      ],
      "metadata": {
        "id": "WbtdARbmStAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_class(model, model_name, x_train, y_train, x_test, y_test):\n",
        "  model.fit(x_train,y_train)\n",
        "  y_test_pred = model.predict(x_test)\n",
        "  y_train_pred = model.predict(x_train)\n",
        "\n",
        "  score_train = model.score(x_train,y_train)\n",
        "  score_test = model.score(x_test,y_test)\n",
        "\n",
        "  f1_test = f1_score(y_test, y_test_pred)\n",
        "  f1_train = f1_score(y_train, y_train_pred)\n",
        "\n",
        "  # con_mtx = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "  precision_test = precision_score(y_test, y_test_pred,zero_division=0)\n",
        "  precision_train= precision_score(y_train, y_train_pred,zero_division=0)\n",
        "\n",
        "  recall_test = recall_score(y_test, y_test_pred)\n",
        "  recall_train = recall_score(y_train, y_train_pred)\n",
        "\n",
        "  scores = {\n",
        "      'Score': {'train':score_train, 'val': score_test},\n",
        "      'F1': {'train':f1_train, 'val': f1_test},\n",
        "      'Precision': {'train':precision_train, 'val': precision_test},\n",
        "      'Recall': {'train':recall_train, 'val': recall_test},\n",
        "      'AP': None,\n",
        "      'PR_curve': None,\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    y_test_pred_proba = model.predict_proba(x_test)\n",
        "    y_train_pred_proba = model.predict_proba(x_train)\n",
        "\n",
        "    ohe = OneHotEncoder(sparse=False)\n",
        "    y_train_oh = ohe.fit_transform(y_train.reshape((-1, 1))) \n",
        "    y_test_oh = ohe.fit_transform(y_test.reshape((-1, 1)))\n",
        "\n",
        "    ap_test = average_precision_score(y_test_oh, y_test_pred_proba)\n",
        "    ap_train = average_precision_score(y_train_oh, y_train_pred_proba)\n",
        "    \n",
        "    pr_curve_test = precision_recall_curve(y_test, y_test_pred_proba[:, -1])\n",
        "    pr_curve_train = precision_recall_curve(y_train, y_train_pred_proba[:, -1])\n",
        "  \n",
        "    scores['AP'] = {'train':ap_train, 'val': ap_test}\n",
        "    scores['PR_curve'] = {'train':pr_curve_train, 'val': pr_curve_test}\n",
        "  except AttributeError as e:\n",
        "    print(e)\n",
        "  \n",
        "  ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred, normalize = 'true')\n",
        "  plt.title(model_name)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  return scores\n",
        "\n",
        "def plot_score_generic(model_names, model_scores_t, model_scores_v, score_name):\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel(score_name)\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_score(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='score')\n",
        "\n",
        "def plot_f1_score(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='f1')\n",
        "\n",
        "def plot_score_precision(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='precision')\n",
        "\n",
        "def plot_score_recall(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='recall')\n",
        "  \n",
        "def plot_score_ap(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='AP')\n",
        "\n",
        "def plot_curve_generic(model_names, model_scores_t, model_scores_v, x_score_name, y_score_name):\n",
        "  for mn, (precision, recall, thresholds) in zip(model_names, model_scores_t):\n",
        "    plt.plot(recall, precision, '--', label = f'{mn} training')\n",
        "  for mn, (precision, recall, thresholds) in zip(model_names, model_scores_v):\n",
        "    plt.plot(recall, precision, '-', label = f'{mn} validation')\n",
        "  \n",
        "  plt.ylabel(y_score_name)\n",
        "  plt.xlabel(x_score_name)\n",
        "  \n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  "
      ],
      "metadata": {
        "id": "VbVfIV1ES4IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_class(model, params,features, target):\n",
        "  scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "                    'precision': make_scorer(precision_score, average = 'macro', zero_division=0),\n",
        "                    'recall': make_scorer(recall_score, average = 'macro'), \n",
        "                    'f1': make_scorer(f1_score, average = 'macro')}\n",
        "  model_grid = GridSearchCV(model, params,scoring=scoring,refit='f1')\n",
        "  model_grid.fit(features, target)\n",
        "  df_grid = pd.DataFrame(model_grid.cv_results_)\n",
        "  df_grid['params'] = list(map(lambda n: str(list(n.values())), df_grid['params']))\n",
        "  return model_grid, df_grid\n",
        "\n",
        "def plot_cv_metrics(model_name, model_params, model_f1, model_recall, model_precision, model_accuracy ):\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.set_size_inches(30,10)\n",
        "  plt.plot(model_params, model_f1, label = 'f1')\n",
        "  plt.plot(model_params, model_recall, label = 'recall')\n",
        "  plt.plot(model_params, model_precision, label = 'precision' )\n",
        "  plt.plot(model_params, model_accuracy, label = 'accuracy' )\n",
        "  plt.xticks(rotation=90, ha='right')\n",
        "  plt.title(model_name)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close() "
      ],
      "metadata": {
        "id": "5_67iGCfS95m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_reg(x, y,**kws):\n",
        "    r, _ = stats.pearsonr(x, y)\n",
        "    ax = plt.gca()\n",
        "    ax.annotate(\"r = {:.1f}\".format(r),\n",
        "                xy=(0.2, 0.95),\n",
        "                xycoords=ax.transAxes, size = 20)\n",
        "     \n",
        "def corr_class(x, y,**kws):\n",
        "    r, _ = stats.pearsonr(x, y)\n",
        "    ax = plt.gca()\n",
        "    pos = (.1, .9) if kws['label'] == 'Yes' else (.5,.9)\n",
        "\n",
        "    ax.annotate(\"{}: r = {:.2f}\".format(kws['label'],r),\n",
        "                xy=pos, xycoords=ax.transAxes)    \n",
        "def plot_pair_grid_ref(df, hue):\n",
        "  g = sns.PairGrid(df, hue, size=4)\n",
        "  g.map_upper(sns.regplot, scatter_kws={'s':6},line_kws = {'color': 'black'})\n",
        "  g.map_lower(corr_reg)\n",
        "  g.map_lower(sns.kdeplot)\n",
        "  g.map_diag(sns.histplot)\n",
        "def plot_pair_grid_class(df, hue):\n",
        "  g = sns.PairGrid(df,hue, size=4)\n",
        "  g.map_upper(sns.regplot, scatter_kws={'s':6},line_kws = {'color': 'black'})\n",
        "  g.map_lower(corr_class)\n",
        "  g.map_lower(sns.kdeplot,gridsize=150)\n",
        "  g.map_diag(sns.histplot)  "
      ],
      "metadata": {
        "id": "8Rc7TDCLTIU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_model(features, target, mode, grid, df, hue):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
        "\n",
        "  models_fit_info = None\n",
        "\n",
        "  if mode == 'regression':\n",
        "    plot_pair_grid_ref(df, hue = None)\n",
        "\n",
        "    models_fit_info = {\n",
        "        'LinearRegression': {'model': LinearRegression(),'param':{}},\n",
        "        'RandomForestRegressor': {'model': RandomForestRegressor(),'param' :{'n_estimators':[50,100,150,200,300,400,500],'max_depth':[1,2,4,8,16,64,128,512, 640,768,896]}},\n",
        "        'DecisionTreeRegressor': {'model': DecisionTreeRegressor(),'param' :{'max_features': [0.1,0.2,0.3,0.6,0.7,0.8,1],'max_depth':[1,2,4,8,16,64,128,512,640,768,896]} },\n",
        "        'Lasso': {'model': linear_model.Lasso(), 'param' : {'alpha': [0.1,0.2,0.3, 0.4,0.5,0.7,1.0, 2.0,2.3, 2.7,3.0, 3.3, 3.7,4.0]}},\n",
        "        'Ridge': {'model': Ridge(),'param' : {'alpha': [0.1,0.2,0.3, 0.4,0.5,0.7,1.0, 2.0,2.3, 2.7,3.0]}},\n",
        "        'KNeighborsRegressor': {'model': KNeighborsRegressor(), 'param': {'n_neighbors' : [2,3,5,10,15,17,19,21,23,25],'weights' : ('uniform', 'distance')}},\n",
        "        'GradientBoostingRegressor' : {'model': GradientBoostingRegressor(),'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'AdaBoostRegressor' : {'model' : AdaBoostRegressor(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'XGBRegressor' : {'model' : xgb.XGBRegressor(), 'param' : {'objective' :['reg:squarederror'],'max_depth':[1,2,4,8,16,64,128,512],'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7]}}\n",
        "    }\n",
        "    # iterate all models, do grid search and final training and evaluations\n",
        "    for model_name, model_info in models_fit_info.items():\n",
        "      if grid == 'Yes':\n",
        "        grid_results,model_grid =  grid_reg(model_info['model'], model_info['param'],features, target)\n",
        "        #cv_model_with_best_params = model_grid_model.best_estimator_\n",
        "        model_info['best_param'] = model_grid.best_params_\n",
        "        model_class = model_info['model'].__class__\n",
        "        new_model_with_best_params = model_class(**model_info['best_param'])\n",
        "        model_info['model'] = new_model_with_best_params\n",
        "        #plor metrics r2 for cv_model\n",
        "        plot_cv_r2(model_name + 'CV', grid_results['params'], grid_results['mean_test_r2'])\n",
        "        #plot mae, mse for cv_model\n",
        "        plot_mae_mse(model_name + 'CV', grid_results['params'], grid_results['mean_test_mae'], grid_results['root_mean_test_mse'])\n",
        "      model = model_info['model']\n",
        "      metrics_dict = test_model_reg(model, model_name, x_train, y_train, x_test, y_test)\n",
        "      model_info['metrics'] = metrics_dict\n",
        "\n",
        "    model_names = list(models_fit_info.keys())\n",
        "\n",
        "    for score_name, score_plot_fn in zip(['r2', 'rmse', 'mae'], [plot_r2, plot_rmse, plot_mae]):\n",
        "      model_score_tra = [models_fit_info[mn]['metrics'][score_name]['train'] for mn in model_names]\n",
        "      model_score_val = [models_fit_info[mn]['metrics'][score_name]['val'] for mn in model_names]\n",
        "      \n",
        "      score_plot_fn(model_names, model_score_tra, model_score_val)\n",
        "\n",
        "    return  models_fit_info\n",
        "\n",
        "  if mode == 'classification':\n",
        "    plot_pair_grid_class(df, hue)\n",
        "    models_fit_info = {\n",
        "        'DecisionTree': {'model': DecisionTreeClassifier(),'param' : {'max_depth':[1,2,4,8,16,64,128,512],'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,1]}},\n",
        "        'RandomForest': {'model': RandomForestClassifier(),'param' : {'max_depth':[1,2,4,6,10,328,16,64,128,256,512],'criterion':('gini', 'entropy')}},\n",
        "        'SVM': {'model': svm.SVC(),'param' : {'C': [0.1, 1, 10, 100, 1000,1200,1400,1600,1800]}},\n",
        "        'LogisticRegression': {'model': LogisticRegression(),'param' :{'C':[0.5,1.0, 2.0,3.0,10.0,20.0]}},\n",
        "        'KNeighborsClassifier': {'model': KNeighborsClassifier(),'param': {'n_neighbors' : [3,5,10,12,15,20,25],'weights' : ('uniform', 'distance') }},\n",
        "        'GradientBoostingClassifier' : {'model' : GradientBoostingClassifier(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'AdaBoostClassifier' : {'model' : AdaBoostClassifier(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'XGBClassifier' : {'model' : xgb.XGBClassifier(),'param' : {'max_depth':[1,2,4,8,16,64,128,512],'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7]}},\n",
        "        'GaussianNB' : {'model' : GaussianNB(), 'param':{}}\n",
        "    }\n",
        "  \n",
        "    for model_name, model_info in models_fit_info.items():\n",
        "      if grid == 'Yes':\n",
        "        model_grid, df_grid = grid_class(model_info['model'], model_info['param'],features, target)\n",
        "        \n",
        "        model_info['best_param'] = model_grid.best_params_\n",
        "        model_class = model_info['model'].__class__\n",
        "        new_model_with_best_params = model_class(**model_info['best_param'])\n",
        "        \n",
        "        model_info['model'] = new_model_with_best_params\n",
        "        #plot metrics for cv_model\n",
        "        plot_cv_metrics(model_name + 'CV', df_grid['params'], df_grid['mean_test_f1'], df_grid['mean_test_recall'], df_grid['mean_test_precision'], df_grid['mean_test_accuracy'])\n",
        "\n",
        "      model = model_info['model']\n",
        "      metrics_dict = test_model_class(model, model_name, x_train, y_train, x_test, y_test)\n",
        "      model_info['metrics'] = metrics_dict\n",
        "\n",
        "    model_names = list(models_fit_info.keys())\n",
        "\n",
        "    # for score_name, score_plot_fn in zip(['score', 'f1', 'precision', 'recall'], [plot_score, plot_f1_score, plot_score_precision,plot_score_recall]):\n",
        "    for score_name in ['Score', 'F1', 'Precision', 'Recall', 'AP']:\n",
        "      selected_model_names = []\n",
        "      model_score_tra = []\n",
        "      model_score_val = []\n",
        "      \n",
        "      for mn in model_names:\n",
        "        model_metrics = models_fit_info[mn]['metrics'][score_name]\n",
        "        if model_metrics is None:\n",
        "          continue\n",
        "\n",
        "        selected_model_names.append(mn)\n",
        "        model_score_tra.append(model_metrics['train'])\n",
        "        model_score_val.append(model_metrics['val'])\n",
        "\n",
        "      plot_score_generic(selected_model_names, model_score_tra, model_score_val, score_name)\n",
        "    \n",
        "    for score_name, (x_score_name, y_score_name) in [('PR_curve', ('Recall', 'Precision'))]:\n",
        "      selected_model_names = []\n",
        "      model_score_tra = []\n",
        "      model_score_val = []\n",
        "      \n",
        "      for mn in model_names:\n",
        "        model_metrics = models_fit_info[mn]['metrics'][score_name]\n",
        "        if model_metrics is None:\n",
        "          continue\n",
        "\n",
        "        selected_model_names.append(mn)\n",
        "        model_score_tra.append(model_metrics['train'])\n",
        "        model_score_val.append(model_metrics['val'])\n",
        "      \n",
        "      plot_curve_generic(selected_model_names, model_score_tra, model_score_val, x_score_name=x_score_name, y_score_name=y_score_name)\n",
        "      \n",
        "\n",
        "    return  models_fit_info  \n",
        "      "
      ],
      "metadata": {
        "id": "mATib3zKTmuH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}