{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Download libaries**"
      ],
      "metadata": {
        "id": "y-Uve0OX-QUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mDwT5AZxWyzZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "from functools import partial\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import cross_val_score,train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "from sklearn.svm import SVR\n",
        "import matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions for testing and evaluating regression models, as well as for plotting the performance metrics such as R-squared, MAE, and RMSE, using Matplotlib** "
      ],
      "metadata": {
        "id": "k3R5ooLWBRGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_reg(model, model_name, x_train, y_train, x_test, y_test):\n",
        "  # Train the model using the training data\n",
        "  model.fit(x_train,y_train)\n",
        "\n",
        "  # Use the trained model to make predictions on the testing and training data\n",
        "  y_test_pred = model.predict(x_test)\n",
        "  y_train_pred = model.predict(x_train)\n",
        "\n",
        "  # Compute R^2 scores for both training and testing data\n",
        "  r2_train = r2_score(y_train, y_train_pred)\n",
        "  r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "  # Compute mean absolute error (MAE) scores for both training and testing data\n",
        "  mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "  mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "  # Compute root mean squared error (RMSE) scores for both training and testing data\n",
        "  rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "  rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "\n",
        "  # Store the scores in a dictionary\n",
        "  scores = {\n",
        "      'r2': {'train':r2_train, 'val': r2_test},\n",
        "      'rmse': {'train':rmse_train, 'val': rmse_test},\n",
        "      'mae': {'train':mae_train, 'val': mae_test}\n",
        "  }\n",
        "\n",
        "  # Plot the predicted vs. ground truth values for the testing data\n",
        "  plt.scatter(y_test,y_test_pred, s=5)\n",
        "  plt.xlabel('GT')\n",
        "  plt.ylabel('Predicted')\n",
        "  plt.gca().set_aspect('equal')\n",
        "  plt.title(model_name)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  \n",
        "  # Return the scores dictionary\n",
        "  return scores\n",
        "\n",
        "def plot_r2(model_names, model_scores_t, model_scores_v):\n",
        "  # Plot the R^2 scores for the training and validation data for each model\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel(r'$R^2$')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.ylim(-0.1, 1)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_score_reg(model_names, model_scores_t, model_scores_v):\n",
        "  # Plot a generic score (e.g. R^2, accuracy) for the training and validation data for each model\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('score')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_mae(model_names, model_scores_t, model_scores_v):\n",
        "  # Plot the mean absolute error (MAE) scores for the training and validation data for each model\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('MAE')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_rmse(model_names, model_scores_t, model_scores_v):\n",
        "  # Plot the root mean squared error (RMSE) scores for the training and validation data for each model\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()  "
      ],
      "metadata": {
        "id": "4l3K-Y0vX2iX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions to test and plot various evaluation metrics for machine learning models, including score, F1 score, precision, recall, average precision, and precision-recall curve**"
      ],
      "metadata": {
        "id": "-rJDIDRM_Z2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_class(model, model_name, x_train, y_train, x_test, y_test):\n",
        "  # Fit the model on the training data\n",
        "  model.fit(x_train,y_train)\n",
        "\n",
        "  # Use the trained model to make predictions on the training and validation data\n",
        "  y_test_pred = model.predict(x_test)\n",
        "  y_train_pred = model.predict(x_train)\n",
        "\n",
        "  # Calculate the score of the model on the training and validation data\n",
        "  score_train = model.score(x_train,y_train)\n",
        "  score_test = model.score(x_test,y_test)\n",
        "\n",
        "  # Calculate the F1 score of the model on the training and validation data\n",
        "  f1_test = f1_score(y_test, y_test_pred) #, average='micro')\n",
        "  f1_train = f1_score(y_train, y_train_pred) #, average='micro')\n",
        "\n",
        "  # Calculate the precision of the model on the training and validation data\n",
        "  precision_test = precision_score (y_test, y_test_pred,zero_division=0) #, average='micro')\n",
        "  precision_train= precision_score (y_train, y_train_pred,zero_division=0) #, average='micro')\n",
        "\n",
        "  # Calculate the recall of the model on the training and validation data\n",
        "  recall_test = recall_score(y_test, y_test_pred )#, average='micro')\n",
        "  recall_train = recall_score(y_train, y_train_pred )#,  average='micro')\n",
        "\n",
        "  # Create a dictionary to store the scores of the model\n",
        "  scores = {\n",
        "      'Score': {'train':score_train, 'val': score_test},\n",
        "      'F1': {'train':f1_train, 'val': f1_test},\n",
        "      'Precision': {'train':precision_train, 'val': precision_test},\n",
        "      'Recall': {'train':recall_train, 'val': recall_test},\n",
        "      'AP': None,\n",
        "      'PR_curve': None,\n",
        "  }\n",
        "\n",
        "  try:\n",
        "\n",
        "    # If the model has a predict_proba method, use it to make predictions and calculate the average precision score\n",
        "    y_test_pred_proba = model.predict_proba(x_test)\n",
        "    y_train_pred_proba = model.predict_proba(x_train)\n",
        "\n",
        "    # Convert the target values to one-hot encoding format\n",
        "    ohe = OneHotEncoder(sparse_output=False)\n",
        "    y_train_oh = ohe.fit_transform(y_train.reshape((-1, 1))) \n",
        "    y_test_oh = ohe.fit_transform(y_test.reshape((-1, 1)))\n",
        "\n",
        "    # Calculate the average precision score of the model on the training and validation data\n",
        "    ap_test = average_precision_score(y_test_oh, y_test_pred_proba)\n",
        "    ap_train = average_precision_score(y_train_oh, y_train_pred_proba)\n",
        "    \n",
        "    # Calculate the precision-recall curve of the model on the training and validation data\n",
        "    pr_curve_test = precision_recall_curve(y_test, y_test_pred_proba[:, -1])\n",
        "    pr_curve_train = precision_recall_curve(y_train, y_train_pred_proba[:, -1])\n",
        "\n",
        "    # Add the average precision score and the precision-recall curve to the scores dictionary\n",
        "    scores['AP'] = {'train':ap_train, 'val': ap_test}\n",
        "    scores['PR_curve'] = {'train':pr_curve_train, 'val': pr_curve_test}\n",
        "  except AttributeError as e:\n",
        "    # If the model does not have a predict_proba method, print an error message\n",
        "    print(e)\n",
        "  \n",
        "  # Display a confusion matrix for the model's predictions on the validation data\n",
        "  ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred, normalize = 'true')\n",
        "  plt.title(model_name)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  # Return the scores dictionary\n",
        "  return scores\n",
        "\n",
        "def plot_score_generic(model_names, model_scores_t, model_scores_v, score_name):\n",
        "  # Plot the training scores\n",
        "  plt.plot(model_names, model_scores_t, '*', label = 'training')\n",
        "\n",
        "  # Plot the validation scores\n",
        "  plt.plot(model_names, model_scores_v, '*', label = 'validation')\n",
        "\n",
        "  plt.ylabel(score_name)\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "# A convenience function to plot scores with the default name \"score\"\n",
        "def plot_score(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='score')\n",
        "\n",
        "# A convenience function to plot F1 scores\n",
        "def plot_f1_score(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='f1')\n",
        "\n",
        "# A convenience function to plot precision scores\n",
        "def plot_score_precision(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='precision')\n",
        "\n",
        "# A convenience function to plot recall scores\n",
        "def plot_score_recall(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='recall')\n",
        "\n",
        "# A convenience function to plot average precision scores  \n",
        "def plot_score_ap(model_names, model_scores_t, model_scores_v):\n",
        "  plot_score_generic(model_names, model_scores_t, model_scores_v, score_name='AP')\n",
        "\n",
        "# A generic function to plot precision-recall curves for different models\n",
        "def plot_curve_generic(model_names, model_scores_t, model_scores_v, x_score_name, y_score_name):\n",
        "  # Plot the precision-recall curve for each model on the training set\n",
        "  for mn, (precision, recall, thresholds) in zip(model_names, model_scores_t):\n",
        "    plt.plot(recall, precision, '--', label = f'{mn} training')\n",
        "    # Plot the precision-recall curve for each model on the validation set\n",
        "  for mn, (precision, recall, thresholds) in zip(model_names, model_scores_v):\n",
        "    plt.plot(recall, precision, '-', label = f'{mn} validation')\n",
        "  \n",
        "  plt.ylabel(y_score_name)\n",
        "  plt.xlabel(x_score_name)\n",
        "  \n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "hpIWRElcYEOA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defines a function called \"merge_results_dict\" that takes two dictionaries as input, and merges the values of the second dictionary into the first one, provided that the keys match and the values are either a list or a numpy array**"
      ],
      "metadata": {
        "id": "aam0QOQsDMMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_results_dict(res_merge_into, res_merge_from):\n",
        "  # If res_merge_into is empty, copy over lists/arrays from res_merge_from\n",
        "  if len(res_merge_into) == 0:\n",
        "    for k, v_from in res_merge_from.items():\n",
        "      if type(v_from) not in [list, np.ndarray]:\n",
        "        continue\n",
        "      res_merge_into[k] = v_from.copy()\n",
        "    return\n",
        "    \n",
        "   # Merge lists/arrays from res_merge_from into res_merge_into\n",
        "  for k, v_from in res_merge_from.items():\n",
        "    if type(v_from) not in [list, np.ndarray]:\n",
        "      continue\n",
        "      \n",
        "    if k not in res_merge_into:\n",
        "      raise ValueError(f'Unexpected key in new result dict: {k}')\n",
        "\n",
        "    v_into = res_merge_into[k]\n",
        "\n",
        "    if type(v_from) == list and type(v_into) == list:\n",
        "      v_into.extend(v_from)\n",
        "    elif type(v_from) == np.ndarray and type(v_into) == np.ndarray:\n",
        "      v_new = np.concatenate((v_into, v_from))\n",
        "      res_merge_into[k] = v_new\n",
        "    # elif type(v_into) == list:\n",
        "    #   v_into.append(v_from)\n",
        "    # else:\n",
        "    #   v_new = [v_into, v_from]\n",
        "    #   res_merge_into[k] = v_new"
      ],
      "metadata": {
        "id": "mvvRLlPdYHi-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions for performing grid search with cross-validation and plotting evaluation metrics for regression models** "
      ],
      "metadata": {
        "id": "R07u2pm1Boj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_reg(model, params, features, target):\n",
        "  # Define scoring metrics\n",
        "  scoring = {'r2': make_scorer(r2_score),\n",
        "           'rmse': make_scorer(mean_squared_error),\n",
        "           'mae': make_scorer(mean_absolute_error)\n",
        "           }\n",
        "\n",
        "  # Check if parameters are a list\n",
        "  if type(params) == list:\n",
        "    # If the parameters are a list, we need to loop through each dictionary in the list\n",
        "    results = {}  \n",
        "    found_params = {}  \n",
        "    for params_i in params:\n",
        "      # Create a dictionary with the previous best parameters and the current parameters we want to test\n",
        "      test_params = found_params.copy() \n",
        "      for k,v in params_i.items():\n",
        "        test_params[k] = v\n",
        "\n",
        "      # Perform a grid search with the current parameters  \n",
        "      model_grid = GridSearchCV(model, test_params, scoring=scoring, refit='r2') \n",
        "      model_grid.fit(features, target)\n",
        "\n",
        "      # Update the found_params dictionary with the best parameters from the grid search\n",
        "      found_params = {k:[v] for k, v in  model_grid.best_params_.items()}\n",
        "\n",
        "      # Merge the current grid search results with the previous results\n",
        "      merge_results_dict(results, model_grid.cv_results_)\n",
        "\n",
        "    # Convert the results dictionary to a pandas DataFrame   \n",
        "    grid_results = pd.DataFrame(results)\n",
        "  else:\n",
        "    # If the parameters are a dictionary, we can perform a single grid search\n",
        "    model_grid = GridSearchCV(model, params, scoring=scoring, refit='r2')\n",
        "    model_grid.fit(features, target)\n",
        "    grid_results = pd.DataFrame(model_grid.cv_results_)\n",
        "\n",
        "  # Add a column for the root mean squared error  \n",
        "  grid_results['root_mean_test_mse'] = list(map(lambda n: sqrt(n), grid_results['mean_test_rmse']))\n",
        "\n",
        "  # Convert the parameter dictionaries to strings and create a list of parameter names\n",
        "  params_list = grid_results['params']\n",
        "  our_list = []\n",
        "  features_list = list(set().union(*(d.keys() for d in params_list)))\n",
        "  pairs = {}\n",
        "\n",
        "  # Loop through each parameter dictionary and create a string representation\n",
        "  for params_dict in params_list:\n",
        "    our_str = \"\"\n",
        "    for i, k in enumerate(features_list):\n",
        "      if params_dict.get(k) is not None:\n",
        "        our_str += chr(i + 65) +':'+ str(params_dict[k]) + \" \"\n",
        "        pairs[k] = chr(i + 65)\n",
        "        \n",
        "    our_list.append(our_str.strip())\n",
        "\n",
        "  # Replace the parameter dictionaries with their string representation\n",
        "  grid_results['params'] = our_list\n",
        "  our_list = grid_results['params']\n",
        "  \n",
        "  return model_grid,grid_results,pairs\n",
        "\n",
        "def plot_cv_r2(model_name, model_params, model_r2,pairs):\n",
        "  #Plots the cross-validation R2 scores of a model across different hyperparameters\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(30,10)\n",
        "    plt.plot(model_params, model_r2, label = 'r2', color='blue')\n",
        "    plt.xticks(rotation=90, ha='right')\n",
        "    plt.title(model_name)\n",
        "\n",
        "    # Create list of parameter labels from pairs dictionary\n",
        "    parameter_labels = []\n",
        "    for k, v in pairs.items():\n",
        "      parameter_labels.append(f'{k}={v}')\n",
        "\n",
        "    # Create text from parameter labels and add it to plot\n",
        "    text = '\\n'.join(parameter_labels)\n",
        "    plt.legend()\n",
        "    ax.text(1.05, 0.95, text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_mae_mse(model_name, model_params, model_mse, model_mae, pairs):\n",
        "    # Create a figure and axis object\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    # Set the figure size\n",
        "    fig.set_size_inches(30,10)\n",
        "    \n",
        "    # Plot the mean absolute error and root mean squared error\n",
        "    plt.plot(model_params, model_mae, label='mae')\n",
        "    plt.plot(model_params, model_mse, label='rmse')\n",
        "    \n",
        "    # Rotate the x-axis tick labels by 90 degrees and align them to the right\n",
        "    plt.xticks(rotation=90, ha='right')\n",
        "    \n",
        "    # Set the title of the plot to the model name\n",
        "    plt.title(model_name)\n",
        "    \n",
        "    # Create a list of parameter labels based on the key-value pairs in the 'pairs' dictionary\n",
        "    parameter_labels = []\n",
        "    for k, v in pairs.items():\n",
        "        parameter_labels.append(f'{k}={v}')\n",
        "    \n",
        "    # Join the parameter labels with newline characters and assign to the 'text' variable\n",
        "    text = '\\n'.join(parameter_labels)\n",
        "    \n",
        "    # Add a legend to the plot\n",
        "    plt.legend()\n",
        "    \n",
        "    # Add the parameter labels to the plot as text in the upper-right corner\n",
        "    ax.text(1.05, 0.95, text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top')\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "gagirjpfYPkZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defines two functions: \"grid_class\" performs a grid search for a given model and its hyperparameters, and \"plot_cv_metrics\" visualizes the cross-validation metrics for the model**"
      ],
      "metadata": {
        "id": "lpjJkIlJF-8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_class(model, params,features, target):\n",
        "  # Define the scoring metrics for the grid search\n",
        "  scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "                    'precision': make_scorer(precision_score, zero_division=0, average='macro'),\n",
        "                    'recall': make_scorer(recall_score, average='macro'), \n",
        "                    'f1': make_scorer(f1_score, average='macro')}\n",
        "\n",
        "  # Check if params is a list or not. If it's a list, perform grid search for each set of parameters.\n",
        "  if type(params) == list: \n",
        "    results = {}  \n",
        "    found_params = {} # Store the best parameter values found so far \n",
        "    for params_i in params:\n",
        "      test_params = found_params.copy()  #Copy the current best parameters\n",
        "      for k,v in params_i.items(): \n",
        "        test_params[k] = v # Update the copy with the new parameter values\n",
        "\n",
        "      # Perform grid search  \n",
        "      model_grid = GridSearchCV(model, test_params, scoring=scoring, refit='f1') \n",
        "      model_grid.fit(features, target)\n",
        "\n",
        "      found_params = {k:[v] for k, v in  model_grid.best_params_.items()} # Store the best parameter values\n",
        "\n",
        "      merge_results_dict(results, model_grid.cv_results_) # Merge the results dictionary\n",
        "    \n",
        "      \n",
        "    df_grid = pd.DataFrame(results) # Create a dataframe from the results\n",
        "  else:\n",
        "    # Perform grid search\n",
        "    model_grid = GridSearchCV(model, params, scoring=scoring, refit='f1')\n",
        "    model_grid.fit(features, target)\n",
        "    df_grid = pd.DataFrame(model_grid.cv_results_)\n",
        "  \n",
        "  # Convert the parameter dictionaries to strings and replace them in the dataframe\n",
        "  params_list = df_grid ['params']\n",
        "  our_list = []\n",
        "  features_list = list(set().union(*(d.keys() for d in params_list)))\n",
        "  pairs = {}\n",
        "  \n",
        "  for params_dict in params_list:\n",
        "    \n",
        "    our_str = \"\"\n",
        "    for i, k in enumerate(features_list):\n",
        "      if params_dict.get(k) is not None:\n",
        "        our_str += chr(i + 65) +':'+ str(params_dict[k]) + \" \"# Convert the parameter dictionaries to strings\n",
        "        pairs[k] = chr(i + 65) # Store the corresponding character label for each feature\n",
        "        \n",
        "    our_list.append(our_str.strip())\n",
        "\n",
        "  df_grid ['params'] = our_list # Replace the parameter dictionaries with the strings in the dataframe\n",
        "  our_list = df_grid ['params']\n",
        "  \n",
        "  return model_grid, df_grid, pairs\n",
        "\n",
        "def plot_cv_metrics(model_name, model_params, model_f1, model_recall, model_precision, model_accuracy ,pairs):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(30,10)\n",
        "    \n",
        "    # Plot the F1 score, recall, precision, and accuracy\n",
        "    plt.plot(model_params, model_f1, label = 'f1')\n",
        "    plt.plot(model_params, model_recall, label = 'recall')\n",
        "    plt.plot(model_params, model_precision, label = 'precision' )\n",
        "    plt.plot(model_params, model_accuracy, label = 'accuracy' )\n",
        "    \n",
        "    # Rotate the x-axis tick labels by 90 degrees and align them to the right\n",
        "    plt.xticks(rotation=90, ha='right')\n",
        "    \n",
        "    # Set the title of the plot to the model name\n",
        "    plt.title(model_name)\n",
        "    \n",
        "    # Create a list of parameter labels based on the key-value pairs in the 'pairs' dictionary\n",
        "    parameter_labels = []\n",
        "    for k, v in pairs.items():\n",
        "        parameter_labels.append(f'{k}={v}')\n",
        "    \n",
        "    # Join the parameter labels with newline characters and assign to the 'text' variable\n",
        "    text = '\\n'.join(parameter_labels) \n",
        "    \n",
        "    # Add a legend to the plot\n",
        "    plt.legend()   \n",
        "    \n",
        "    # Add the parameter labels to the plot as text in the upper-right corner\n",
        "    ax.text(1.05, 0.95, text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top')  \n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "V3TnjzdsYVoi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for visualizing pairwise relationships between variables in a Pandas DataFrame using seaborn's PairGrid, including scatterplots with linear regression lines and annotations of correlation coefficients**"
      ],
      "metadata": {
        "id": "ZoEbp7mNK-cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_reg(x, y,**kws):\n",
        "\n",
        "  # Calculate the Pearson correlation coefficient between x and y  \n",
        "    r, _ = stats.pearsonr(x, y)\n",
        "\n",
        "    # Get the current axes instance\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Add an annotation to the plot showing the correlation coefficient\n",
        "    ax.annotate(\"r = {:.1f}\".format(r),\n",
        "                xy=(0.2, 0.95),\n",
        "                xycoords=ax.transAxes, size = 20)\n",
        "     \n",
        "def corrfunc(x, y, **kws):\n",
        "     # Calculate the Pearson correlation coefficient between x and y\n",
        "    r, _ = stats.pearsonr(x, y)\n",
        "    # Get the current axes instance\n",
        "    ax = plt.gca()\n",
        "    # Determine the number of annotations already on the plot\n",
        "    n = len([c for c in ax.get_children() if \n",
        "                  isinstance(c, matplotlib.text.Annotation)])\n",
        "    # Determine the position and color of the new annotation based on the hue category\n",
        "    pos = (.1, .9 - .1*n)\n",
        "    color = sns.color_palette()[sns.color_palette().index(kws['color'])]\n",
        "\n",
        "    # Add an annotation to the plot showing the correlation coefficient and hue category\n",
        "    ax.annotate(\"{}: r = {:.2f}\".format(kws['label'], r), xy=pos, xycoords=ax.transAxes, color=color)\n",
        "\n",
        "def plot_pair_grid_ref(df, hue):\n",
        "  # Create a PairGrid with regression plots in the upper triangle\n",
        "  # and kernel density estimates in the lower triangle\n",
        "  g = sns.PairGrid(data=df, hue=hue, height=4, aspect=1.5)\n",
        "  g.map_upper(sns.regplot, scatter_kws={'s':6},line_kws = {'color': 'black'})\n",
        "  g.map_lower(corr_reg)\n",
        "  g.map_lower(sns.kdeplot)\n",
        "  g.map_diag(sns.histplot)\n",
        "def plot_pair_grid_class(df, hue):\n",
        "  # Create a PairGrid with regression plots in the upper triangle\n",
        "  # and annotations of correlation coefficients in the lower triangle\n",
        "  g = sns.PairGrid(data=df, hue=hue, height=4, aspect=1.5)\n",
        "  g.map_upper(sns.regplot, scatter_kws={'s':6},line_kws = {'color': 'black'})\n",
        "  g.map_lower(corrfunc)\n",
        "  g.map_lower(sns.kdeplot,gridsize=150)\n",
        "  g.map_diag(sns.histplot)  "
      ],
      "metadata": {
        "id": "nfNaTne5ZO46"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Function that performs a grid search with cross-validation to find the best hyperparameters for a set of regression or classification models, and returns a dictionary containing information on the models including the model object, best hyperparameters, and evaluation metrics**"
      ],
      "metadata": {
        "id": "8AsNpoT-LEPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_model(features, target, mode, grid, df, hue, models):\n",
        "  # Splitting the dataset into train and test sets with a ratio of 0.2\n",
        "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
        "\n",
        "  # Initializing a variable to store the model fit information\n",
        "  models_fit_info = None\n",
        "\n",
        "  if mode == 'regression':\n",
        "    # If mode is regression, plot a pair grid reference with the given dataframe and hue\n",
        "    plot_pair_grid_ref(df, hue = None)\n",
        "\n",
        "  # Initializing a dictionary to store the models and their hyperparameters\n",
        "    models_fit_info = {\n",
        "        'LinearRegression': {'model': LinearRegression(),'param':{}},\n",
        "        #'RandomForestRegressor': {'model': RandomForestRegressor( n_jobs = 1 ),'param' :{'n_estimators':[50,100,150,200],'max_depth':[1,2,4,8,16,64,128,512]}},\n",
        "        'RandomForestRegressor': {\n",
        "            'model': RandomForestRegressor(n_jobs = -1),\n",
        "            'param': [\n",
        "                {'max_depth': [4,16, 32, 42] },\n",
        "                {'n_estimators': [50,100,150,200,300,400,500] }\n",
        "                ]\n",
        "           },\n",
        "        'DecisionTreeRegressor': {'model': DecisionTreeRegressor(),'param' :{'max_features': [0.1,0.2,0.3],'max_depth':[1,2,4,8,16], 'min_samples_split' :[1,2,3]} },\n",
        "        'Lasso': {'model': linear_model.Lasso(), 'param' : {'alpha': [0.1,0.2,0.3, 0.4,0.5,0.7,1.0, 2.0,2.3, 2.7,3.0, 3.3, 3.7,4.0]}},\n",
        "        'Ridge': {'model': Ridge(),'param' : {'alpha': [0.1,0.2,0.3, 0.4,0.5,0.7,1.0, 2.0,2.3, 2.7,3.0]}},\n",
        "        'KNeighborsRegressor': {'model': KNeighborsRegressor(n_jobs = -1), 'param': {'n_neighbors' : [2,3,5,10,15,17,19,21,23,25],'weights' : ('uniform', 'distance')}},\n",
        "        'GradientBoostingRegressor' : {'model': GradientBoostingRegressor(),'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'AdaBoostRegressor' : {'model' : AdaBoostRegressor(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'XGBRegressor' : {'model' : xgb.XGBRegressor(), 'param' : {'objective' :['reg:squarederror'],'max_depth':[1,2,4,8,16,64,128,512],'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7]}}\n",
        "    }\n",
        "    if models != None:\n",
        "      # Iterate through all models and store their info\n",
        "      for model, model_params in models:\n",
        "        models_fit_info[model.__class__.__name__] = {'model': model, 'param': model_params}\n",
        "    \n",
        "    # Iterate through all models, perform grid search and final training and evaluations\n",
        "    for model_name, model_info in models_fit_info.items():\n",
        "      if grid == 'Yes':\n",
        "\n",
        "        # Perform grid search on the model\n",
        "        model_grid, grid_results,pairs =  grid_reg(model_info['model'], model_info['param'],features, target)\n",
        "        \n",
        "        # Uppdate model info with best parameters\n",
        "        model_info['best_param'] = model_grid.best_params_\n",
        "        model_class = model_info['model'].__class__\n",
        "\n",
        "        # Create a new model instance with best parameters\n",
        "        new_model_with_best_params = model_class(**model_info['best_param'])\n",
        "        model_info['model'] = new_model_with_best_params\n",
        "\n",
        "        # Plot metrics (r2, mae, mse) for cv model\n",
        "        plot_cv_r2(model_name + 'CV', grid_results['params'], grid_results['mean_test_r2'], pairs)\n",
        "        plot_mae_mse(model_name + 'CV', grid_results['params'], grid_results['mean_test_mae'], grid_results['root_mean_test_mse'],pairs)\n",
        "\n",
        "      # Train and evaluate the final model  \n",
        "      model = model_info['model']\n",
        "      metrics_dict = test_model_reg(model, model_name, x_train, y_train, x_test, y_test)\n",
        "      model_info['metrics'] = metrics_dict\n",
        "\n",
        "    # Create a list of model names\n",
        "    model_names = list(models_fit_info.keys())\n",
        "\n",
        "    # Plot r2, rmse, and mae for train and validation sets\n",
        "    for score_name, score_plot_fn in zip(['r2', 'rmse', 'mae'], [plot_r2, plot_rmse, plot_mae]):\n",
        "      model_score_tra = [models_fit_info[mn]['metrics'][score_name]['train'] for mn in model_names]\n",
        "      model_score_val = [models_fit_info[mn]['metrics'][score_name]['val'] for mn in model_names]\n",
        "      \n",
        "      score_plot_fn(model_names, model_score_tra, model_score_val)\n",
        "# Return the models_fit_info dictionary\n",
        "    return  models_fit_info\n",
        "\n",
        "  if mode == 'classification':\n",
        "    # If mode is regression, plot a pair grid reference with the given dataframe and hue\n",
        "    plot_pair_grid_class(df, hue)\n",
        "    # Initializing a dictionary to store the models and their hyperparameters\n",
        "    models_fit_info = {\n",
        "        'DecisionTree': {'model': DecisionTreeClassifier(),'param' : {'max_depth':[1,2,4,8,16,64,128,512],'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,1]}},\n",
        "         #'RandomForest': {'model': RandomForestClassifier(n_jobs = 1),'param' : {'max_depth':[1,2,4,6,10,328,16,64,128,256,512],'criterion':('gini', 'entropy')}},\n",
        "        'RandomForest': \n",
        "        {'model': RandomForestClassifier(n_jobs = -1),\n",
        "         'param' : [{'max_depth':[1,2,4,6,10,328,16,64,128,256,512]}, {'criterion':('gini', 'entropy')}]},\n",
        "        'SVM': {'model': svm.SVC(),'param' : {'C': [0.1, 1, 10]}},\n",
        "        'LogisticRegression': {'model': LogisticRegression(n_jobs = -1),'param' :{'C':[0.5,1.0, 2.0,3.0,10.0,20.0]}},\n",
        "        'KNeighborsClassifier': {'model': KNeighborsClassifier(n_jobs = -1),'param': {'n_neighbors' : [3,5,10,12,15,20,25],'weights' : ('uniform', 'distance') }},\n",
        "        'GradientBoostingClassifier' : {'model' : GradientBoostingClassifier(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'AdaBoostClassifier' : {'model' : AdaBoostClassifier(), 'param' :{'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7], 'n_estimators':[50,100,150,200,300,400,500]}},\n",
        "        'XGBClassifier' : {'model' : xgb.XGBClassifier(),'param' : {'max_depth':[1,2,4,8,16,64,128,512],'learning_rate':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7]}},\n",
        "        'GaussianNB' : {'model' : GaussianNB(), 'param':{}}\n",
        "    }\n",
        "    if models != None:\n",
        "      # Iterate through all models and store their info\n",
        "      for model, model_params in models:\n",
        "        models_fit_info[model.__class__.__name__] = {'model': model, 'param': model_params}\n",
        "\n",
        "    # Iterate through all models, perform grid search and final training and evaluations\n",
        "    for model_name, model_info in models_fit_info.items():\n",
        "      if grid == 'Yes':\n",
        "        # Perform grid search on the model\n",
        "        model_grid, df_grid,pairs = grid_class(model_info['model'], model_info['param'],features, target)\n",
        "      # Uppdate model info with best parameters\n",
        "        model_info['best_param'] = model_grid.best_params_\n",
        "        model_class = model_info['model'].__class__\n",
        "        new_model_with_best_params = model_class(**model_info['best_param'])\n",
        "        # Create a new model instance with best parameters\n",
        "        model_info['model'] = new_model_with_best_params\n",
        "        #Plot metrics for cv_model\n",
        "        plot_cv_metrics(model_name + 'CV', df_grid['params'], df_grid['mean_test_f1'], df_grid['mean_test_recall'], df_grid['mean_test_precision'], df_grid['mean_test_accuracy'],pairs)\n",
        "      # Train and evaluate the final model\n",
        "      model = model_info['model']\n",
        "      metrics_dict = test_model_class(model, model_name, x_train, y_train, x_test, y_test)\n",
        "      model_info['metrics'] = metrics_dict\n",
        "     # Create a list of model names\n",
        "    model_names = list(models_fit_info.keys())\n",
        "\n",
        "    # for score_name, score_plot_fn in zip(['score', 'f1', 'precision', 'recall'], [plot_score, plot_f1_score, plot_score_precision,plot_score_recall]):\n",
        "    # Plot model evaluation scores\n",
        "  for score_name in ['Score', 'F1', 'Precision', 'Recall', 'AP']:\n",
        "    selected_model_names = []\n",
        "    model_score_tra = []\n",
        "    model_score_val = []\n",
        "    \n",
        "    # Collect metrics for each model\n",
        "    for mn in model_names:\n",
        "      model_metrics = models_fit_info[mn]['metrics'][score_name]\n",
        "      if model_metrics is None:\n",
        "            continue\n",
        "\n",
        "      selected_model_names.append(mn)\n",
        "      model_score_tra.append(model_metrics['train'])\n",
        "      model_score_val.append(model_metrics['val'])\n",
        "\n",
        "    # Plot scores using a generic function\n",
        "    plot_score_generic(selected_model_names, model_score_tra, model_score_val, score_name)\n",
        "\n",
        "# Plot PR curves\n",
        "  for score_name, (x_score_name, y_score_name) in [('PR_curve', ('Recall', 'Precision'))]:\n",
        "    selected_model_names = []\n",
        "    model_score_tra = []\n",
        "    model_score_val = []\n",
        "    \n",
        "    # Collect metrics for each model\n",
        "    for mn in model_names:\n",
        "        model_metrics = models_fit_info[mn]['metrics'][score_name]\n",
        "        \n",
        "        if model_metrics is None:\n",
        "            continue\n",
        "\n",
        "        selected_model_names.append(mn)\n",
        "        model_score_tra.append(model_metrics['train'])\n",
        "        model_score_val.append(model_metrics['val'])\n",
        "    \n",
        "    # Plot PR curves using a generic function\n",
        "    plot_curve_generic(selected_model_names, model_score_tra, model_score_val, x_score_name=x_score_name, y_score_name=y_score_name)\n",
        "\n",
        "# Return the model information dictionary\n",
        "  return models_fit_info  \n",
        "      "
      ],
      "metadata": {
        "id": "8LMRRxanZUoF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qw-z5VEbz5ga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let us download file for analyze and training our model**"
      ],
      "metadata": {
        "id": "xGn8vM4aOaaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "MzvfQuTrmZ72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aa1729d5-afa8-4e47-c051-c3758a62e1b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f05dfebe-c26e-469b-b62d-f4491dfc7113\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f05dfebe-c26e-469b-b62d-f4491dfc7113\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data1.csv to data1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['data1.csv']))\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "QhU7xaPLO7aN",
        "outputId": "bc62c03c-ef6a-455f-e554-e86076af0215"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "5  9305-CDSKC  Female              0      No         No       8          Yes   \n",
              "6  1452-KIOVK    Male              0      No        Yes      22          Yes   \n",
              "7  6713-OKOMC  Female              0      No         No      10           No   \n",
              "8  7892-POOKP  Female              0     Yes         No      28          Yes   \n",
              "9  6388-TABGU    Male              0      No        Yes      62          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
              "0  No phone service             DSL             No  ...               No   \n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "3  No phone service             DSL            Yes  ...              Yes   \n",
              "4                No     Fiber optic             No  ...               No   \n",
              "5               Yes     Fiber optic             No  ...              Yes   \n",
              "6               Yes     Fiber optic             No  ...               No   \n",
              "7  No phone service             DSL            Yes  ...               No   \n",
              "8               Yes     Fiber optic             No  ...              Yes   \n",
              "9                No             DSL            Yes  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
              "0          No          No              No  Month-to-month              Yes   \n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "3         Yes          No              No        One year               No   \n",
              "4          No          No              No  Month-to-month              Yes   \n",
              "5          No         Yes             Yes  Month-to-month              Yes   \n",
              "6          No         Yes              No  Month-to-month              Yes   \n",
              "7          No          No              No  Month-to-month               No   \n",
              "8         Yes         Yes             Yes  Month-to-month              Yes   \n",
              "9          No          No              No        One year               No   \n",
              "\n",
              "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check          29.85         29.85    No  \n",
              "1               Mailed check          56.95        1889.5    No  \n",
              "2               Mailed check          53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
              "4           Electronic check          70.70        151.65   Yes  \n",
              "5           Electronic check          99.65         820.5   Yes  \n",
              "6    Credit card (automatic)          89.10        1949.4    No  \n",
              "7               Mailed check          29.75         301.9    No  \n",
              "8           Electronic check         104.80       3046.05   Yes  \n",
              "9  Bank transfer (automatic)          56.15       3487.95    No  \n",
              "\n",
              "[10 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d16ece45-7e94-4694-9d86-59c4cf1309e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9305-CDSKC</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>99.65</td>\n",
              "      <td>820.5</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1452-KIOVK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>22</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card (automatic)</td>\n",
              "      <td>89.10</td>\n",
              "      <td>1949.4</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6713-OKOMC</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>29.75</td>\n",
              "      <td>301.9</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7892-POOKP</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>28</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>104.80</td>\n",
              "      <td>3046.05</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6388-TABGU</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>62</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>56.15</td>\n",
              "      <td>3487.95</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d16ece45-7e94-4694-9d86-59c4cf1309e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d16ece45-7e94-4694-9d86-59c4cf1309e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d16ece45-7e94-4694-9d86-59c4cf1309e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqYbGpIaPBbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSMgzI6QRjov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}